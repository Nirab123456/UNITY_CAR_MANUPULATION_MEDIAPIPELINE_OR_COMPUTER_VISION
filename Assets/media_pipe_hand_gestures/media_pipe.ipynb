{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peaceful_pie.unity_comms import UnityComms\n",
    "from peaceful_pie.unity_comms import UnityComms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unity_comms(port: int):\n",
    "    unity_comms = UnityComms(port)\n",
    "    return unity_comms\n",
    "port = 5000  # Replace with your desired port number\n",
    "unity_comms_instance = unity_comms(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unity_comms_instance \n",
    "unity_comms = unity_comms_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('landmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create a Hands object.\n",
    "mp_hands = mp.solutions.hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# STEP 3: Open the video capture.\n",
    "cap = cv2.VideoCapture(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(action):\n",
    "        # Perform the action based on the provided action index\n",
    "        if action == 0:\n",
    "            unity_comms.GoForward_5000()\n",
    "        elif action == 1:\n",
    "            unity_comms.GoReverse_5000()\n",
    "        elif action == 2:\n",
    "            unity_comms.TurnLeft_5000()\n",
    "        elif action == 3:\n",
    "            unity_comms.TurnRight_5000()\n",
    "        elif action == 4:\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 5:\n",
    "            unity_comms.GoForward_5000()\n",
    "            unity_comms.TurnLeft_5000()\n",
    "        elif action == 6:\n",
    "            unity_comms.GoForward_5000()\n",
    "            unity_comms.TurnRight_5000()\n",
    "        elif action == 7:\n",
    "            unity_comms.GoForward_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 8:\n",
    "            unity_comms.GoReverse_5000()\n",
    "            unity_comms.TurnLeft_5000()\n",
    "        elif action == 9:\n",
    "            unity_comms.GoReverse_5000()\n",
    "            unity_comms.TurnRight_5000()\n",
    "        elif action == 10:\n",
    "            unity_comms.GoReverse_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 11:\n",
    "            unity_comms.GoForward_5000()\n",
    "            unity_comms.TurnLeft_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 12:\n",
    "            unity_comms.GoForward_5000()\n",
    "            unity_comms.TurnRight_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 13:\n",
    "            unity_comms.GoReverse_5000()\n",
    "            unity_comms.TurnLeft_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        elif action == 14:\n",
    "            unity_comms.GoReverse_5000()\n",
    "            unity_comms.TurnRight_5000()\n",
    "            unity_comms.Handbrake_5000()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action index\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WRIST = 0\n",
    "THUMB_CMC = 1\n",
    "THUMB_MCP = 2\n",
    "THUMB_IP = 3\n",
    "THUMB_TIP = 4\n",
    "INDEX_FINGER_MCP = 5\n",
    "INDEX_FINGER_PIP = 6\n",
    "INDEX_FINGER_DIP = 7\n",
    "INDEX_FINGER_TIP = 8\n",
    "MIDDLE_FINGER_MCP = 9\n",
    "MIDDLE_FINGER_PIP = 10\n",
    "MIDDLE_FINGER_DIP = 11\n",
    "MIDDLE_FINGER_TIP = 12\n",
    "RING_FINGER_MCP = 13\n",
    "RING_FINGER_PIP = 14\n",
    "RING_FINGER_DIP = 15\n",
    "RING_FINGER_TIP = 16\n",
    "PINKY_MCP = 17\n",
    "PINKY_PIP = 18\n",
    "PINKY_DIP = 19\n",
    "PINKY_TIP = 20\n",
    "# to go reverse\n",
    "def is_open_palm(points):\n",
    "    if points[THUMB_TIP][1] < points[THUMB_IP][1] and \\\n",
    "        points[INDEX_FINGER_TIP][1] < points[INDEX_FINGER_PIP][1] and \\\n",
    "        points[MIDDLE_FINGER_TIP][1] < points[MIDDLE_FINGER_PIP][1] and \\\n",
    "        points[RING_FINGER_TIP][1] < points[RING_FINGER_PIP][1] and \\\n",
    "        points[PINKY_TIP][1] < points[PINKY_PIP][1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# to go forward\n",
    "def is_index_finger_extended(points):\n",
    "    if points[INDEX_FINGER_TIP][1] < points[INDEX_FINGER_DIP][1] and \\\n",
    "        points[INDEX_FINGER_DIP][1] < points[INDEX_FINGER_PIP][1] and \\\n",
    "        points[INDEX_FINGER_PIP][1] < points[INDEX_FINGER_MCP][1] and \\\n",
    "        points[INDEX_FINGER_MCP][1] < points[WRIST][1]:\n",
    "        if is_open_palm(points) == True:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "# to go forward and left\n",
    "def  is_index_and_middle_finger_extended(points):\n",
    "    if is_index_finger_extended(points)== True :\n",
    "        if points[MIDDLE_FINGER_TIP][1] < points[MIDDLE_FINGER_DIP][1] and \\\n",
    "            points[MIDDLE_FINGER_DIP][1] < points[MIDDLE_FINGER_PIP][1] and \\\n",
    "            points[MIDDLE_FINGER_PIP][1] < points[MIDDLE_FINGER_MCP][1] and \\\n",
    "            points[MIDDLE_FINGER_MCP][1] < points[WRIST][1]:\n",
    "            if is_open_palm(points) == True:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the BGR frame to RGB.\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # # Flip the image horizontally for a mirrored view.\n",
    "    # image = cv2.flip(image, 1)\n",
    "\n",
    "    # Process the image with the Hands model.\n",
    "    results = mp_hands.process(image)\n",
    "\n",
    "    # Draw hand landmarks on the image.\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp.solutions.hands.HAND_CONNECTIONS\n",
    "            )\n",
    "            \n",
    "            # Convert landmarks to a list of points\n",
    "            points = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                points.append((x, y))\n",
    "                print(points)\n",
    "\n",
    "            # Check if open palm gesture is detected\n",
    "\n",
    "            # Check if the index finger is extended\n",
    "            if is_index_finger_extended(points):\n",
    "                action_2 = step(2)\n",
    "                print(\"Index finger extended\")\n",
    "\n",
    "            if is_open_palm(points):\n",
    "                action_1 = step(4)\n",
    "                print(\"Open palm detected\")              \n",
    "\n",
    "            if is_index_and_middle_finger_extended(points):\n",
    "                action_5 = step(5)      \n",
    "                print(\"Index and middle finger extended\")\n",
    "\n",
    "                            \n",
    "            # # Check if open palm gesture is detected\n",
    "            # if is_open_palm(points)==True:\n",
    "            #     print(\"Open palm detected\")\n",
    "            # if is_index_finger_extended(points):\n",
    "            #     print(\"Index finger extended\")\n",
    "    # Convert the RGB image back to BGR for displaying.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Display the image with hand landmarks.\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
